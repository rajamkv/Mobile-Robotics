{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2\n",
    "\n",
    "## Topic : Stereo reconstruction and Non-linear optimization\n",
    "\n",
    "#### Instructions\n",
    "<ul>\n",
    "    <li> The second project of the course is designed to get you familiar with stereo reconstruction, and non-linear optimization </li>\n",
    "    <li> Use python for this project. PILLOW and OpenCV are permitted for image I/O. </li>\n",
    "    <li> Submit this notebook as a zipped file on moodle. The format should be $<$team_id$>$_$<$team_ name$>$.zip. Both members have to submit this zip file. </li>\n",
    "    <li> A seperate report is not needed if you're coding in the notebook itself. Please provide adequate descriptions of the approaches you've taken. Also mention work distribution for the two members. </li>\n",
    "    <li> Refer to the late day policy. Start early </li> \n",
    "    <li> Download data from here: https://iiitaphyd-my.sharepoint.com/:f:/g/personal/aryan_sakaria_students_iiit_ac_in/Er5C7351IAlFsvwHUesFeSQBQtlSiAS7AORSEJT2qH_8_w?e=ol98k9  </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work:\n",
    "\n",
    "#### part a \n",
    "\n",
    "-> 1st question by Mohit (Stereo dense reconstruction)\n",
    "\n",
    "-> 2nd question by Raja  (Motion estimation using iterative PnP)\n",
    "\n",
    "#### part b\n",
    "\n",
    "-> By Raja and Mohit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### PART 1: Stereo dense reconstruction\n",
    "\n",
    "3-D point clouds are very useful in robotics for several tasks such as object detection, motion estimation (3D-3D matching or 3D-2D matching), SLAM, and other forms of scene understanding.  Stereo camerasprovide  us  with  a  convenient  way  to  generate  dense  point  clouds.Densehere,  in  contrast  tosparse,means all the image points are used for the reconstruction.  In this part of the assignment you will begenerating a dense 3D point cloud reconstruction of a scene from stereo images.\n",
    "\n",
    "#### Procedure: \n",
    "\n",
    "<ol>\n",
    "    <li> Generate a disparity map for each stereo pair.  Use OpenCV (e.g.  StereoSGBM) for this.  Notethat the images provided are already rectified and undistorted. </li>\n",
    "    <li> Then, using the camera parameters and baseline information generate colored point clouds fromeach disparity map.  Some points will have invalid disparity values, so ignore them.  Use [Open3D]for storing your point clouds. </li>\n",
    "    <li> Register (or transform) all the generated point clouds into your world frame by using the providedground truth poses. </li>\n",
    "    <li> Visualize the registered point cloud data, in color.  Use Open3D for this </li>\n",
    "</ol>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries:\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import normalize #normalizing gives better results. Experiment with this\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252,) (21, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "def read_transformations(filename='./mr2020_project_data/poses.txt'):\n",
    "    f = open(filename, 'r')\n",
    "    lines = f.readlines()\n",
    "    transformation_list = []\n",
    "    for i in range(len(lines)):\n",
    "        transformation_list_temp = lines[i].split()\n",
    "        temp_rot = [] \n",
    "        temp_rot.append( (transformation_list_temp[0:4] ) ) \n",
    "        temp_rot.append( (transformation_list_temp[4:8]  ) ) \n",
    "        temp_rot.append( (transformation_list_temp[8:12]  ) ) \n",
    "        transformation_list.append(temp_rot)\n",
    "    return transformation_list\n",
    "tr_list=np.array(read_transformations())\n",
    "tr_list=tr_list.flatten()\n",
    "tr_mat_list = list(map(float, tr_list)) \n",
    "tr_mat_list=np.array(tr_mat_list)\n",
    "tr_mat_list=tr_mat_list.reshape(21,3,4)\n",
    "print(tr_list.shape,tr_mat_list.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide explanation in this cell: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the image pair 1\n",
      "Process Done\n",
      "Processing the image pair 2\n",
      "Process Done\n",
      "Processing the image pair 3\n",
      "Process Done\n",
      "Processing the image pair 4\n",
      "Process Done\n",
      "Processing the image pair 5\n",
      "Process Done\n",
      "Processing the image pair 6\n",
      "Process Done\n",
      "Processing the image pair 7\n",
      "Process Done\n",
      "Processing the image pair 8\n",
      "Process Done\n",
      "Processing the image pair 9\n",
      "Process Done\n",
      "Processing the image pair 10\n",
      "Process Done\n",
      "Processing the image pair 11\n",
      "Process Done\n",
      "Processing the image pair 12\n",
      "Process Done\n",
      "Processing the image pair 13\n",
      "Process Done\n",
      "Processing the image pair 14\n",
      "Process Done\n",
      "Processing the image pair 15\n",
      "Process Done\n",
      "Processing the image pair 16\n",
      "Process Done\n",
      "Processing the image pair 17\n",
      "Process Done\n",
      "Processing the image pair 18\n",
      "Process Done\n",
      "Processing the image pair 19\n",
      "Process Done\n",
      "Processing the image pair 20\n",
      "Process Done\n",
      "Processing the image pair 21\n",
      "Process Done\n",
      "(7021724, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here\n",
    "K = np.array([[7.070912e+02, 0.000000e+00, 6.018873e+02],\n",
    "             [0.000000e+00, 7.070912e+02, 1.831104e+02],\n",
    "             [0.000000e+00, 0.000000e+00, 1.000000e+00]])\n",
    "f=K[0][0]\n",
    "b=0.53790448812\n",
    "\n",
    "pcd_gl=o3d.geometry.PointCloud()\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd_list=[]\n",
    "\n",
    "for i in range(21):\n",
    "    # Read Corresponding Images\n",
    "    img_1 = cv2.imread('./mr2020_project_data/img2/00000004'+str(i+60)+'.png')\n",
    "    img_2 = cv2.imread('./mr2020_project_data/img3/00000004'+str(i+60)+'.png')\n",
    "    print(\"Processing the image pair \"+str(i+1))\n",
    "    # Disparities using cv2.StereoSGBM\n",
    "    stereo = cv2.StereoSGBM_create(minDisparity= -39,\n",
    "           numDisparities = 144,\n",
    "           blockSize = 5,\n",
    "           uniquenessRatio = 10,\n",
    "           speckleWindowSize = 150,\n",
    "           speckleRange = 32,\n",
    "           disp12MaxDiff = 1,\n",
    "           P1 = 8*3*5**2,\n",
    "           P2 =32*3*5**2,\n",
    "           preFilterCap=63) \n",
    "    min_disp = -39\n",
    "    num_disp = 144     \n",
    "    disparity= stereo.compute(img_1, img_2).astype(np.float32) / 64\n",
    "    disparity = (disparity-min_disp)/num_disp\n",
    "    Dim = disparity.shape\n",
    "    \n",
    "    # Q matrix\n",
    "    Q = np.array([[ 1,  0,  0, -Dim[1]/2],\n",
    "                  [ 0,  -1,  0, Dim[0]/2],\n",
    "                  [ 0,  0,  0, f],\n",
    "                  [ 0,  0,  1/b, 0]])\n",
    "    disparity_pts=[]\n",
    "    for p in range(Dim[0]):\n",
    "        for q in range(Dim[1]):\n",
    "            disparity_pts.append([q,p,disparity[p,q],1])\n",
    "    disparity_pts = np.array(disparity_pts)\n",
    "    \n",
    "    # Camera points w.r.t Disparity points\n",
    "    cam_pts=[np.matmul(Q,m) for m in disparity_pts]\n",
    "    cam_pts=np.array([c/c[3]for c in cam_pts])\n",
    "    colors = cv2.cvtColor(img_1, cv2.COLOR_BGR2RGB)    # Colors\n",
    "    mask = disparity >= disparity.min()\n",
    "    colors = colors[mask]/255\n",
    "    \n",
    "    # Generating World points from Cmaera points using Camera Poses  \n",
    "    world_pts=np.matmul(tr_mat_list[i],cam_pts.T)\n",
    "    world_pts[0]=-world_pts[0]\n",
    "    print(\"Process Done\")\n",
    "    # PCD generation\n",
    "    pcd.points = o3d.utility.Vector3dVector(world_pts.T)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    pcd_list.append(pcd)\n",
    "    pcd_gl=pcd_gl+pcd\n",
    "    \n",
    "pts=np.asarray(pcd_gl.points)\n",
    "clrs=np.asarray(pcd_gl.colors)\n",
    "mask = ((abs(pts[:,1]) < 1500) & (abs(pts[:,2]) < 1500) & (abs(pts[:,0]) < 1500))\n",
    "pts=pts[mask]\n",
    "clrs=clrs[mask]\n",
    "print(np.shape(pts))\n",
    "\n",
    "\n",
    "pcd_gl.points=o3d.utility.Vector3dVector(pts)\n",
    "pcd_gl.colors=o3d.utility.Vector3dVector(clrs)\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd_gl])\n",
    "o3d.io.write_point_cloud(\"Output.pcd\", pcd_gl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### PART 2: Motion estimation using iterative PnP\n",
    "\n",
    "Using the generated reconstruction from the previous part, synthesize a new image taken by a virtualmonocular camera fixed at any arbitrary position and orientation.  Your task in this part is to recoverthis pose using an iterative Perspective-from-n-Points (PnP) algorithm. \n",
    "\n",
    "#### Procedure: \n",
    "\n",
    "<ol>\n",
    "    <li> Obtain a set of 2D-3D correspondences between the the image and the point cloud.  Since hereyou’re generating the image, this should be easy to obtain. </li>\n",
    "    <li> For this set of correspondences compute the total reprojection error c= $\\sum_{i} ‖x_i−P_{k}X_i‖^2 $    where $P_{k}= K[R_{k}|t_{k}]$, $X_{i}$ is the 3D point in the world frame, $x_{i}$ is its corresponding projection. </li>\n",
    "    <li> Solve for the pose $T_{k}$ that minimizes this non-linear reprojection error using a Gauss-Newton (GN)scheme.  Recall that in GN we start with some initial estimated value $x_{o}$ and iteratively refine the estimate using $x_{1}$= $∆x+x_0$, where $∆x$ is obtained by solving the normal equations $J^{T}J∆x$= -$J^{T}e$, until convergence.The main steps in this scheme are computing the corresponding Jacobians and updating the estimates correctly.  For our problem,  use a 12×1 vector parameterization for $T_{k}$(the top 3×4submatrix).  Run the optimization for different choices of initialization and report your observations. </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gauss_newton(P,x_gt,X,N,tol): \n",
    "    Loss=[]\n",
    "    for i in range(N):\n",
    "        x = (P@X.T).T\n",
    "        A = x_gt[:,0]/x_gt[:,2] - x[:,0]/x[:,2]\n",
    "        B = x_gt[:,1]/x_gt[:,2] - x[:,1]/x[:,2]\n",
    "        res = (np.hstack((A,B))).reshape(-1,1)\n",
    "        k = (res.T@res/2/len(X)).item(0);\n",
    "        \n",
    "        print(\"\\nLoss at Iteration \"+str(i)+\" is --\",k)\n",
    "        Loss.append(k)\n",
    "        J = Jacobian(x,X);\n",
    "        del_p = np.linalg.inv(J.T@J)@J.T@res;\n",
    "        \n",
    "        P = (P.reshape(12,1) - del_p).reshape(3,4);\n",
    "        if(np.linalg.norm(del_p)<tol):\n",
    "            break;\n",
    "    Loss = np.array(Loss)\n",
    "    return P,Loss, i\n",
    "\n",
    "def Jacobian(x,X):\n",
    "    L = len(X);\n",
    "    X[:,0] = X[:,0]/x[:,2]\n",
    "    X[:,1] = X[:,1]/x[:,2]\n",
    "    X[:,2] = X[:,2]/x[:,2]\n",
    "    X[:,3] = X[:,3]/x[:,2]\n",
    "    x[:,0] = x[:,0]/x[:,2]\n",
    "    x[:,1] = x[:,1]/x[:,2]    \n",
    "    a1 = np.vstack((x[:,0]*X[:,0],x[:,0]*X[:,1]))\n",
    "    a2 = np.vstack((x[:,0]*X[:,2],x[:,0]*X[:,3]))\n",
    "    A = (np.vstack((a1,a2))).T    \n",
    "    b1 = np.vstack((x[:,1]*X[:,0],x[:,1]*X[:,1]))\n",
    "    b2 = np.vstack((x[:,1]*X[:,2],x[:,1]*X[:,3]))\n",
    "    B = (np.vstack((b1,b2))).T    \n",
    "    zeros = np.zeros((L,4))\n",
    "    J_x = np.hstack((-X,np.hstack((zeros,A))))\n",
    "    J_y = np.hstack((zeros,np.hstack((-X,B))))\n",
    "    J = np.vstack((J_x,J_y))\n",
    "    return J\n",
    "\n",
    "def DLT(x,X):\n",
    "    x[:,0] = x[:,0]/x[:,2];\n",
    "    x[:,1] = x[:,1]/x[:,2];    \n",
    "    a1 = np.vstack((x[:,0]*X[:,0],x[:,0]*X[:,1]))\n",
    "    a2 = np.vstack((x[:,0]*X[:,2],x[:,0]*X[:,3]))\n",
    "    A = (np.vstack((a1,a2))).T    \n",
    "    b1 = np.vstack((x[:,1]*X[:,0],x[:,1]*X[:,1]))\n",
    "    b2 = np.vstack((x[:,1]*X[:,2],x[:,1]*X[:,3]))\n",
    "    B = (np.vstack((b1,b2))).T    \n",
    "    zeros = np.zeros((len(X),4))\n",
    "    Ax = np.hstack((-X,np.hstack((zeros,A))))\n",
    "    Ay = np.hstack((zeros,np.hstack((-X,B))))   \n",
    "    M = np.vstack((Ax,Ay))\n",
    "    U,D,VT = np.linalg.svd(M)\n",
    "    P = np.array(VT[-1]).reshape(3,4)\n",
    "    P = P/P[-1,-1]\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------Ground Truths--------------------------------------------------\n",
      "P_GT :\n",
      "  [[-8.90929517e+02  5.38387637e+01 -2.56109933e+02 -1.53083396e+05]\n",
      " [-3.68165080e+01  7.13415332e+02 -1.52284250e+02  2.00006057e+01]\n",
      " [-4.11338164e-01  4.10740947e-02 -9.10556891e-01 -2.77880277e+01]]\n",
      "\n",
      "T_GT  :\n",
      "  [[-9.09854768e-01  4.11782636e-02  4.12878417e-01 -1.92843773e+02]\n",
      " [ 5.44537786e-02  9.98307203e-01  2.04332712e-02  7.22435448e+00]\n",
      " [-4.11338164e-01  4.10740947e-02 -9.10556891e-01 -2.77880277e+01]] \n",
      "\n",
      "\n",
      "--------------------------------------------------Optimization--------------------------------------------------\n",
      "\n",
      "Loss at Iteration 0 is -- 22866961692.909214\n",
      "\n",
      "Loss at Iteration 1 is -- 145583660.95846012\n",
      "\n",
      "Loss at Iteration 2 is -- 217809.41798015666\n",
      "\n",
      "Loss at Iteration 3 is -- 34833.26519634125\n",
      "\n",
      "Loss at Iteration 4 is -- 68.44563162579314\n",
      "\n",
      "Loss at Iteration 5 is -- 17.910054171127065\n",
      "\n",
      "Loss at Iteration 6 is -- 1.4323182506227732\n",
      "\n",
      "Loss at Iteration 7 is -- 1.1888279118833935\n",
      "\n",
      "Loss at Iteration 8 is -- 1.1880573011573765\n",
      "\n",
      "Loss at Iteration 9 is -- 1.1880552654023897\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------Final Output--------------------------------------------------\n",
      "\n",
      "P_Output =  [[-8.90928613e+02  5.38386591e+01 -2.56107873e+02 -1.53083294e+05]\n",
      " [-3.68143194e+01  7.13415117e+02 -1.52279387e+02  2.01611247e+01]\n",
      " [-4.11338164e-01  4.10740947e-02 -9.10556891e-01 -2.77880277e+01]]\n",
      "\n",
      "T_Output =  [[-9.09853490e-01  4.11781156e-02  4.12881330e-01 -1.92843628e+02]\n",
      " [ 5.44568739e-02  9.98306900e-01  2.04401488e-02  7.22458150e+00]\n",
      " [-4.11338164e-01  4.10740947e-02 -9.10556891e-01 -2.77880277e+01]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N=21\n",
    "T=read_transformations()\n",
    "\n",
    "pcd = o3d.io.read_point_cloud(\"Output.pcd\") # Read the point cloud\n",
    "points = np.array(pcd.points)\n",
    "pcd_points=np.hstack((points,np.ones((len(points),1))))\n",
    "\n",
    "X_gt = pcd_points[0::10,:]\n",
    "T_gt = np.eye(4,4)\n",
    "T_gt[:3,:4] = T[0]\n",
    "T_gt = np.linalg.inv(T_gt)\n",
    "P_gt = K@T_gt[:3,:4]\n",
    "x_gt = (P_gt@X_gt.T).T\n",
    "P_dlt = DLT(x_gt[:10,:],X_gt[:10,:])\n",
    "\n",
    "print(\"-\"*50 + \"Ground Truths\" + \"-\"*50)\n",
    "print(\"P_GT :\\n \",P_gt)\n",
    "print(\"\\nT_GT  :\\n \",np.linalg.inv(K)@P_gt,\"\\n\\n\")\n",
    "\n",
    "print(\"-\"*50 + \"Optimization\" + \"-\"*50)\n",
    "P_op, Cost, it_conv = Gauss_newton(P_dlt,x_gt,X_gt,1000,1e-4)\n",
    "P_op = P_gt[-1,-1]*P_op/P_op[-1,-1] \n",
    "print(\"\\n\\n\")\n",
    "\n",
    "plt.figure(figsize=(8,8));\n",
    "plt.plot(range(it_conv+1), Cost[0:it_conv+1]);\n",
    "plt.title('Loss vs No of Iterations')\n",
    "\n",
    "print(\"-\"*50 + \"Final Output\" + \"-\"*50)\n",
    "print(\"\\nP_Output = \",P_op)\n",
    "print(\"\\nT_Output = \",np.linalg.inv(K)@P_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 - Part B:\n",
    "\n",
    "## 1. SfM pipeline (`6 mark`)\n",
    "\n",
    "To get the context of below questions, take a look at the code above: The same questions have been asked at different places above as comments in the code.\n",
    "\n",
    "1. `0.5 mark` **Basics** - How do we know this (`camera_ind`) information in practical setting? In other words, how do we know observations in `points_2d` belong to which camera. Explain. \n",
    "    - Ans-1 - Basics: In practical cases we will take the images at different poses so we will know the pose/location so that knowing the camera_ind for each point\n",
    "2. `0.5 mark` **Basics** - How do we know this (`point_ind`) information in practical setting?  In other words, how do we know observations in `points_2d` belong to which 3D point. Explain.\n",
    "    - Ans-2 - Basics: As previous we know the camera poses so we can find the correspondences using sift or other cv functions so that we can find the 3d-point using the triangulation because we know the camera points too , thus mapping from 2d-3d will make sure that we know the 2d-3d correspondances \n",
    "3. `0.5 mark` **Transformations** - `project()` function: In the `project()` function, would it make any difference if I do translate first, then rotate? Why/why not?\n",
    "    - Ans-3 - Transformations: Yes because rotation and translation is done with respect to a specific origin , so if we make the translation 1st then the origin is translated and the rotation is done by that origin not the previous one .\n",
    "\n",
    "4. `0.5 mark` **Jacobian** - `bundle_adjustment_sparsity()` function: m above is not \"M*N\" (*2) unlike our lecture notes. Why is that so?\n",
    "    - Ans-4 - Jacobian: here m is total number of point values in whole images , which is take M images and N number of points in each image then it is finally equal to \"M*N\"(*2) only but here all the images donot consist of same number of points which is true in class problem so here total number of points should be given\n",
    "5. `2 mark` **Jacobian & Parameters** - `bundle_adjustment_sparsity()` function: \n",
    "    1.  Why are we doing `n_cameras * 9` here instead of `n_cameras * 12`? Recollect: Every individual motion Jacobian was (1*)12 in our lecture notes.  \n",
    "        - Ans 5.1 - Jacobian & Parameters: in class we took projection matrix P we took as $3x4=12$ paramenters , but here we took angle rotaion = 6 parametes + 3 intrinsics of camera (focal length + 2 distortions) so 9\n",
    "    2. Ignoring the scale parameters, what was the number of unknown parameters in our lecture notes in terms of `n_cameras` and `n_points`? What is it here in the code? Is it different? If so, what is and why? [Link of notes](https://www.notion.so/Stereo-Structure-from-Motion-9fdd81e4194f4803ac9ba7552df56470).\n",
    "        - Ans 5.2 - Jacobian & Parameters: In class the number of unknowns for each camera=12 , here 9 , and for each new point it is 3 , here also it is same only , so unknowns in class lecture = n_camera * 12 + n_points * 3 here it is n_camera * 9 + n_points * 3 where n_camera is number of cameras and n_points is (number_of_images x number_of_points_per_image)/number_of_times_each_point_is_seen\n",
    "6. `2 mark` **Sparsity, Residual Vector & Jacobian** - `bundle_adjustment_sparsity()` function: Explain what you understand from above 6 lines of code by coding a simple toy example yourself to illustrate how it is different from what you've learnt in class. ([Coding toy example + elaborating in words]- both are compulsory.)\n",
    "    - Ans 6 - Sparsity, Residual Vector & Jacobian: \n",
    "        1. it shows the sparsity of sparsity of jacobian where we set the locations where there is non-zero value to 1 ,for example n unknown parameters , m points we have then we have jac of (2m,n) size where non-zeros are only at a place where the parameters are used to predict secific point \n",
    "        \n",
    "        2. residual size is 2m\n",
    "        \n",
    "        3. jacobian also has a different structure compared to class and we used scipy function to speed up the computations based on sparsity of the matrix\n",
    "        \n",
    "\n",
    "## 2. Initializing R,t and 3D points for SfM given 2 images (`4 mark`)\n",
    "\n",
    "Using OpenCV functions, mention how you would initialize R,t (poses) and 3D points for SfM given 2 images and K matrix. You don't need to implement it, just mention function names with input/output arguments clearly and briefly explain what they do (You don't need to give detailed answers). A sample answer could be as follows:\n",
    "\n",
    "**Ans 2:**\n",
    "\n",
    "1. we can use surf or sift or orb which returns keypoints and descriptors taking image and hessian threshold as input kp and des are float points\n",
    "\n",
    "    surf = cv2.xfeatures2d.SURF_create(hessianThreshold = 1000, extended = 1)\n",
    "\n",
    "    kp, des = surf.detectAndCompute(test_img, None)\n",
    "     - where as sift donot take hessian as input \n",
    " \n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    kp, des = sift.detectAndCompute(test_img, None)\n",
    "   \n",
    "2. Now we got two sets of descriptors so to find correspondences we use knnmatcher with k=2 knnmatcher(des1,des2,2) (k=2 because correspondances between 2 images and des are descripted above step)function -> BFmatcher() for initialisation and knnmatcher for correpondances as said previously\n",
    "\n",
    "\n",
    "3. apply ratio test and find best matches between neighbours p1 and p2\n",
    "\n",
    "\n",
    "4. Then we will send it to F,mask=cv2.findFundamentalMat(p1,p2,cv2.FM_LMEDS) to find F or we can use normalised 8-point algo which does the same \n",
    "\n",
    "\n",
    "5. Now from K,F we find E as $E=K^T * F * K$\n",
    "\n",
    "\n",
    "6. Now we have E,K now decompose them into R,t from temp1,R,t,temp2=cv2.recoverPose(E, p1, p2, K)where the 1st and last output values are not used here we use 2nd 3rd values as R,t input is E,K,p1,p2(points corresponding)\n",
    "\n",
    "\n",
    "7. Now we use triangulation to find 3d points for SFM "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
