{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2\n",
    "\n",
    "## Topic : Stereo reconstruction and Non-linear optimization\n",
    "\n",
    "#### Instructions\n",
    "<ul>\n",
    "    <li> The second project of the course is designed to get you familiar with stereo reconstruction, and non-linear optimization </li>\n",
    "    <li> Use python for this project. PILLOW and OpenCV are permitted for image I/O. </li>\n",
    "    <li> Submit this notebook as a zipped file on moodle. The format should be $<$team_id$>$_$<$team_ name$>$.zip. Both members have to submit this zip file. </li>\n",
    "    <li> A seperate report is not needed if you're coding in the notebook itself. Please provide adequate descriptions of the approaches you've taken. Also mention work distribution for the two members. </li>\n",
    "    <li> Refer to the late day policy. Start early </li> \n",
    "    <li> Download data from here: https://iiitaphyd-my.sharepoint.com/:f:/g/personal/aryan_sakaria_students_iiit_ac_in/Er5C7351IAlFsvwHUesFeSQBQtlSiAS7AORSEJT2qH_8_w?e=ol98k9  </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### PART 1: Stereo dense reconstruction\n",
    "\n",
    "3-D point clouds are very useful in robotics for several tasks such as object detection, motion estimation (3D-3D matching or 3D-2D matching), SLAM, and other forms of scene understanding.  Stereo camerasprovide  us  with  a  convenient  way  to  generate  dense  point  clouds.Densehere,  in  contrast  tosparse,means all the image points are used for the reconstruction.  In this part of the assignment you will begenerating a dense 3D point cloud reconstruction of a scene from stereo images.\n",
    "\n",
    "#### Procedure: \n",
    "\n",
    "<ol>\n",
    "    <li> Generate a disparity map for each stereo pair.  Use OpenCV (e.g.  StereoSGBM) for this.  Notethat the images provided are already rectified and undistorted. </li>\n",
    "    <li> Then, using the camera parameters and baseline information generate colored point clouds fromeach disparity map.  Some points will have invalid disparity values, so ignore them.  Use [Open3D]for storing your point clouds. </li>\n",
    "    <li> Register (or transform) all the generated point clouds into your world frame by using the providedground truth poses. </li>\n",
    "    <li> Visualize the registered point cloud data, in color.  Use Open3D for this </li>\n",
    "</ol>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries:\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import normalize #normalizing gives better results. Experiment with this\n",
    "import cv2\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252,) (21, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "def read_transformations(filename='./mr2020_project_data/poses.txt'):\n",
    "    f = open(filename, 'r')\n",
    "    lines = f.readlines()\n",
    "    transformation_list = []\n",
    "    for i in range(len(lines)):\n",
    "        transformation_list_temp = lines[i].split()\n",
    "        temp_rot = [] \n",
    "        temp_rot.append( (transformation_list_temp[0:4] ) ) \n",
    "        temp_rot.append( (transformation_list_temp[4:8]  ) ) \n",
    "        temp_rot.append( (transformation_list_temp[8:12]  ) ) \n",
    "        transformation_list.append(temp_rot)\n",
    "    return transformation_list\n",
    "tr_list=np.array(read_transformations())\n",
    "tr_list=tr_list.flatten()\n",
    "tr_mat_list = list(map(float, tr_list)) \n",
    "tr_mat_list=np.array(tr_mat_list)\n",
    "tr_mat_list=tr_mat_list.reshape(21,3,4)\n",
    "print(tr_list.shape,tr_mat_list.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide explanation in this cell: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7021724, 3)\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "K = np.array([[7.070912e+02, 0.000000e+00, 6.018873e+02],\n",
    "             [0.000000e+00, 7.070912e+02, 1.831104e+02],\n",
    "             [0.000000e+00, 0.000000e+00, 1.000000e+00]])\n",
    "f=K[0][0]\n",
    "b=0.53790448812\n",
    "pcd_gl=o3d.geometry.PointCloud()\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd_list=[]\n",
    "for i in range(21):\n",
    "    img_1 = cv2.imread('./mr2020_project_data/img2/00000004'+str(i+60)+'.png')\n",
    "    img_2 = cv2.imread('./mr2020_project_data/img3/00000004'+str(i+60)+'.png')\n",
    "    \n",
    "    win_size = 5\n",
    "    blockSize= 5\n",
    "    min_disp = -39\n",
    "    num_disp = 144 \n",
    "    \n",
    "    stereo = cv2.StereoSGBM_create(minDisparity= min_disp,\n",
    "           numDisparities = num_disp,\n",
    "           blockSize = 5,\n",
    "           uniquenessRatio = 10,\n",
    "           speckleWindowSize = 150,\n",
    "           speckleRange = 32,\n",
    "           disp12MaxDiff = 1,\n",
    "           P1 = 8*3*blockSize**2,\n",
    "           P2 =32*3*blockSize**2,\n",
    "           preFilterCap=63) \n",
    "        \n",
    "    disparity= stereo.compute(img_1, img_2).astype(np.float32) / 64\n",
    "    disparity = (disparity-min_disp)/num_disp\n",
    "    Dim = disparity.shape\n",
    "    Q = np.array([[ 1,  0,  0, -Dim[1]/2],\n",
    "                  [ 0,  -1,  0, Dim[0]/2],\n",
    "                  [ 0,  0,  0, f],\n",
    "                  [ 0,  0,  1/b, 0]])\n",
    "    disparity_pts=[]\n",
    "    for p in range(Dim[0]):\n",
    "        for q in range(Dim[1]):\n",
    "            disparity_pts.append([q,p,disparity[p,q],1])\n",
    "    disparity_pts = np.array(disparity_pts)\n",
    "    cam_pts=[np.matmul(Q,m) for m in disparity_pts]\n",
    "    cam_pts=np.array([c/c[3]for c in cam_pts])\n",
    "    colors = cv2.cvtColor(img_1, cv2.COLOR_BGR2RGB)\n",
    "    mask = disparity >= disparity.min()\n",
    "    colors = colors[mask]\n",
    "    colors=colors/255\n",
    "    world_pts=np.matmul(tr_mat_list[i],cam_pts.T)\n",
    "    world_pts[0]=-world_pts[0]\n",
    "        \n",
    "    pcd.points = o3d.utility.Vector3dVector(world_pts.T)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    pcd_list.append(pcd)\n",
    "    pcd_gl=pcd_gl+pcd\n",
    "    \n",
    "pts=np.asarray(pcd_gl.points)\n",
    "clrs=np.asarray(pcd_gl.colors)\n",
    "mask = ((-1500 <= pts[:,1]) & (pts[:,1] < 1500) &\n",
    "         (-1500 <= pts[:,2]) & (pts[:,2] < 1500) &\n",
    "        (-1500 <= pts[:,0]) & (pts[:,0] < 1500))\n",
    "pts=pts[mask]\n",
    "print(np.shape(pts))\n",
    "clrs=clrs[mask]\n",
    "pcd_gl.points=o3d.utility.Vector3dVector(pts)\n",
    "pcd_gl.colors=o3d.utility.Vector3dVector(clrs)\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd_gl])\n",
    "\n",
    "o3d.io.write_point_cloud(\"Out.pcd\", pcd_gl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### PART 2: Motion estimation using iterative PnP\n",
    "\n",
    "Using the generated reconstruction from the previous part, synthesize a new image taken by a virtualmonocular camera fixed at any arbitrary position and orientation.  Your task in this part is to recoverthis pose using an iterative Perspective-from-n-Points (PnP) algorithm. \n",
    "\n",
    "#### Procedure: \n",
    "\n",
    "<ol>\n",
    "    <li> Obtain a set of 2D-3D correspondences between the the image and the point cloud.  Since hereyou’re generating the image, this should be easy to obtain. </li>\n",
    "    <li> For this set of correspondences compute the total reprojection error c= $\\sum_{i} ‖x_i−P_{k}X_i‖^2 $    where $P_{k}= K[R_{k}|t_{k}]$, $X_{i}$ is the 3D point in the world frame, $x_{i}$ is its corresponding projection. </li>\n",
    "    <li> Solve for the pose $T_{k}$ that minimizes this non-linear reprojection error using a Gauss-Newton (GN)scheme.  Recall that in GN we start with some initial estimated value $x_{o}$ and iteratively refine the estimate using $x_{1}$= $∆x+x_0$, where $∆x$ is obtained by solving the normal equations $J^{T}J∆x$= -$J^{T}e$, until convergence.The main steps in this scheme are computing the corresponding Jacobians and updating the estimates correctly.  For our problem,  use a 12×1 vector parameterization for $T_{k}$(the top 3×4submatrix).  Run the optimization for different choices of initialization and report your observations. </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pcd(file_name):\n",
    "    pcd = o3d.io.read_point_cloud(file_name) # Read the point cloud\n",
    "    points = np.asarray(pcd.points)\n",
    "    pcd_points=np.hstack((points,np.ones((len(points),1))))\n",
    "    return pcd_points\n",
    "\n",
    "X_gt = read_pcd(\"Out.pcd\")\n",
    "X_gt = X_gt[0::10,:]\n",
    "T_gt = np.eye(4,4)\n",
    "T_gt[:3,:4] = T[0]\n",
    "T_gt = np.linalg.inv(T_gt)\n",
    "P_gt = K@T_gt[:3,:4]\n",
    "x_gt = (P_gt@X_gt.T).T\n",
    "\n",
    "def DLT(x,X):\n",
    "    x[:,0] = x[:,0]/x[:,2];\n",
    "    x[:,1] = x[:,1]/x[:,2];\n",
    "    L = len(X);\n",
    "    zeros = np.zeros((L,4))\n",
    "    A = (np.vstack((x[:,0]*X[:,0],np.vstack((x[:,0]*X[:,1],np.vstack((x[:,0]*X[:,2],x[:,0]*X[:,3]))))))).T\n",
    "    B = (np.vstack((x[:,1]*X[:,0],np.vstack((x[:,1]*X[:,1],np.vstack((x[:,1]*X[:,2],x[:,1]*X[:,3]))))))).T\n",
    "    Ax = np.hstack((-X,np.hstack((zeros,A))));\n",
    "    Ay = np.hstack((zeros,np.hstack((-X,B))));    \n",
    "    M = np.vstack((Ax,Ay))\n",
    "    U,D,VT = np.linalg.svd(M);\n",
    "    P = np.array(VT[-1]).reshape(3,4);\n",
    "    P = P/P[-1,-1]\n",
    "    return P\n",
    "\n",
    "\n",
    "def residual(x,x_gt):\n",
    "    A = x_gt[:,0]/x_gt[:,2] - x[:,0]/x[:,2]\n",
    "    B = x_gt[:,1]/x_gt[:,2] - x[:,1]/x[:,2]\n",
    "    res = (np.hstack((A,B))).reshape(-1,1)\n",
    "    return res\n",
    "\n",
    "def Jacobian(x,X):\n",
    "    L = len(X);\n",
    "    X[:,0] = X[:,0]/x[:,2]\n",
    "    X[:,1] = X[:,1]/x[:,2]\n",
    "    X[:,2] = X[:,2]/x[:,2]\n",
    "    X[:,3] = X[:,3]/x[:,2]\n",
    "    x[:,0] = x[:,0]/x[:,2]\n",
    "    x[:,1] = x[:,1]/x[:,2]\n",
    "    zeros = np.zeros((L,4))\n",
    "    A = (np.vstack((x[:,0]*X[:,0],np.vstack((x[:,0]*X[:,1],np.vstack((x[:,0]*X[:,2],x[:,0]*X[:,3]))))))).T\n",
    "    B = (np.vstack((x[:,1]*X[:,0],np.vstack((x[:,1]*X[:,1],np.vstack((x[:,1]*X[:,2],x[:,1]*X[:,3]))))))).T\n",
    "    J_x = np.hstack((-X,np.hstack((zeros,A))));\n",
    "    J_y = np.hstack((zeros,np.hstack((-X,B))));\n",
    "    J = np.vstack((J_x,J_y))\n",
    "    return J\n",
    "\n",
    "\n",
    "def Gauss_newton(P,x_gt,X,N,tol): \n",
    "    Cost = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        x = (P@X.T).T\n",
    "        res = residual(x,x_gt) \n",
    "        Cost[i] = (res.T@res/2/len(X)).item(0);\n",
    "        if(i==0):\n",
    "            print(\"\\nInitial Cost (in terms of MSE) = \",Cost[0])\n",
    "        J = Jacobian(x,X);\n",
    "        H = J.T@J;\n",
    "        update = np.linalg.inv(H)@J.T@res;\n",
    "        P = (P.reshape(12,1) - update).reshape(3,4);\n",
    "        if(np.linalg.norm(update)<tol):\n",
    "            print(\"\\nGN has converged\")\n",
    "            break;\n",
    "    return P, Cost, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "P_dlt = DLT(x_gt[:10,:],X_gt[:10,:]);\n",
    "\n",
    "print(\"P_GT = \")\n",
    "print(P_gt)\n",
    "print(\"\\nT_GT = \")\n",
    "print(np.linalg.inv(K)@P_gt)\n",
    "\n",
    "print(\"\\nInitialisation using P_DLT = \")\n",
    "print(P_dlt)\n",
    "\n",
    "P_op, Cost, it_conv = Gauss_newton(P_dlt,x_gt,X_gt,1000,1e-4)\n",
    "P_op = P_gt[-1,-1]*P_op/P_op[-1,-1] \n",
    "\n",
    "print(\"\\nFinal Cost (in terms of MSE) = \",Cost[it_conv])\n",
    "print(\"\\niterations to converge = \",it_conv+1)\n",
    "print(\"\\nP_Output = \")\n",
    "print(P_op)\n",
    "print(\"\\nT_Output = \")\n",
    "print(np.linalg.inv(K)@P_op)\n",
    "\n",
    "plt.figure(figsize=(16,7));\n",
    "plt.plot(range(it_conv+1), Cost[0:it_conv+1]);\n",
    "plt.title('Cost (in terms of MSE) vs Number of Iterations')\n",
    "plt.xlabel('Number of Iterations')\n",
    "plt.ylabel('Cost (in terms of MSE)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
